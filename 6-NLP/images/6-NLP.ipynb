{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vomJzxlCL4yM"
      },
      "source": [
        "---\n",
        "6 Natural Language Processing (NLP)\n",
        "---\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SMC-AAU-CPH/ML-For-Beginners/blob/main/6-NLP/images/6-NLP.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqYNwDJoM_JC",
        "outputId": "20ef22c6-dd91-49f6-827e-a028db1fa4f9"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  # !mkdir -p data\n",
        "  !curl -L -o ~/Downloads/515k-hotel-reviews-data-in-europe.zip https://www.kaggle.com/api/v1/datasets/download/jiashenliu/515k-hotel-reviews-data-in-europe -o Hotel_Reviews.csc\n",
        "  !curl https://raw.githubusercontent.com/cs109/2015lab8/master/data/pride_and_prejudice.txt -o pride.txt\n",
        "  !pip install textblob==0.17.1\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCroLNd_PTQB"
      },
      "source": [
        "# 6.1 Introduction\n",
        "Where we learn about Elisa, Turing Test, and Computational Lingustics, then build a (random) conversational bot.\n",
        "\n",
        "## 6.1.1 The plan\n",
        "\n",
        "Your steps when building a conversational bot:\n",
        "\n",
        "1. Print instructions advising the user how to interact with the bot\n",
        "2. Start a loop\n",
        "    * Accept user input\n",
        "    * If user has asked to exit, then exit\n",
        "    * Process user input and determine response (in this case, the response is a random choice from a list of possible generic responses)\n",
        "    * Print response\n",
        "3. loop back to step 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvjcAphqL4yO",
        "outputId": "ec4e6f1c-1f00-4f98-c756-43b327915775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, I am Marvin, the simple robot.\n",
            "You can end this conversation at any time by typing 'bye'\n",
            "After typing each answer, press 'enter'\n",
            "How are you today?\n",
            "Did you catch the game last night?\n",
            "Funny weather we've been having, isn't it?\n",
            "It was nice talking to you, goodbye!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# This list contains the random responses (you can add your own or translate them into your own language too)\n",
        "random_responses = [\"That is quite interesting, please tell me more.\",\n",
        "                    \"I see. Do go on.\",\n",
        "                    \"Why do you say that?\",\n",
        "                    \"Funny weather we've been having, isn't it?\",\n",
        "                    \"Let's change the subject.\",\n",
        "                    \"Did you catch the game last night?\"]\n",
        "\n",
        "print(\"Hello, I am Marvin, the simple robot.\")\n",
        "print(\"You can end this conversation at any time by typing 'bye'\")\n",
        "print(\"After typing each answer, press 'enter'\")\n",
        "print(\"How are you today?\")\n",
        "\n",
        "while True:\n",
        "    # wait for the user to enter some text\n",
        "    user_input = input(\"> \")\n",
        "    if user_input.lower() == \"bye\":\n",
        "        # if they typed in 'bye' (or even BYE, ByE, byE etc.), break out of the loop\n",
        "        break\n",
        "    else:\n",
        "        response = random.choices(random_responses)[0]\n",
        "    print(response)\n",
        "\n",
        "print(\"It was nice talking to you, goodbye!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQCBDYylL4yP"
      },
      "source": [
        "‚úÖ Stop and consider\n",
        "\n",
        "* Do you think the random responses would 'trick' someone into thinking that the bot actually understood them?\n",
        "* What features would the bot need to be more effective?\n",
        "* If a bot could really 'understand' the meaning of a sentence, would it need to 'remember' the meaning of previous sentences in a conversation too?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Lohr4AL4yQ"
      },
      "source": [
        "# 6.2 [Common NLP tasks](https://paperswithcode.com/area/natural-language-processing) and techniques\n",
        "Where we learn about **tokenization** (splitting text into *tokens*), Embeddings (convert text to numerical data so that similar / related words cluster), Parsing & Part of speech tagging (e.g., as a noun, verb, or adjective), word and phrase frequencies, n-grams (A text can be split into sequences of words of a set length $n$), Noun phrase Extraction, [Sentiment analysis](https://paperswithcode.com/task/sentiment-analysis), inflection, and lemmatization (rooting of words). There are useful databases like WordNet, [GLUE and SST](https://paperswithcode.com/datasets?task=sentiment-analysis) and frameworks from classical NLP (e.g., TextBlob) or Deep Learning (e.g., [Transormers](https://huggingface.co/learn/nlp-course)).\n",
        "\n",
        "üí°Take a look at a [deep learning embeddings on TensorFlow (and recall PCA and T-SNE)](https://projector.tensorflow.org)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsCANW5SL4yQ"
      },
      "source": [
        "### 6.2.1 Exercise  - using `TextBlob` library\n",
        "\n",
        "Let's use a library called TextBlob as it contains helpful APIs for tackling these types of tasks. TextBlob \"stands on the giant shoulders of [NLTK](https://nltk.org) and [pattern](https://github.com/clips/pattern), and plays nicely with both.\" It has a considerable amount of ML embedded in its API.\n",
        "\n",
        "> üí° Note: A useful [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) guide is available for TextBlob that is recommended for experienced Python developers\n",
        "\n",
        "When attempting to identify *noun phrases*, TextBlob offers several options of extractors to find noun phrases.\n",
        "\n",
        "1. Take a look at `ConllExtractor`.\n",
        "\n",
        "   ```python\n",
        "   from textblob import TextBlob\n",
        "   from textblob.np_extractors import ConllExtractor\n",
        "   # import and create a Conll extractor to use later\n",
        "   extractor = ConllExtractor()\n",
        "\n",
        "   # later when you need a noun phrase extractor:\n",
        "   user_input = input(\"> \")\n",
        "   user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified\n",
        "   np = user_input_blob.noun_phrases                                  \n",
        "   ```\n",
        "   > What's going on here? \n",
        "   [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) is \"A noun phrase extractor that uses chunk parsing trained with the ConLL-2000 training corpus.\" ConLL-2000 refers to the 2000 Conference on Computational Natural Language Learning. Each year the conference hosted a workshop to tackle a thorny NLP problem, and in 2000 it was noun chunking. A model was trained on the Wall Street Journal, with \"sections 15-18 as training data (211727 tokens) and section 20 as test data (47377 tokens)\". You can look at the procedures used [here](https://www.clips.uantwerpen.be/conll2000/chunking/) and the [results](https://ifarm.nl/erikt/research/np-chunking.html).\n",
        "   >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFABUBwL4yQ"
      },
      "source": [
        "### 6.2.2 Challenge - improving our bot with NLP\n",
        "\n",
        "In 6.1 we built a very simple Q&A bot. Now, we'll make Marvin a bit more sympathetic by analyzing your input for sentiment and printing out a response to match the sentiment. We'll also need to identify a `noun_phrase` and ask about it.\n",
        "\n",
        "Our steps when building a better conversational bot:\n",
        "\n",
        "1. Print instructions advising the user how to interact with the bot\n",
        "2. Start loop\n",
        "   1. Accept user input\n",
        "   2. If user has asked to exit, then exit\n",
        "   3. Process user input and determine appropriate sentiment response\n",
        "   4. If a noun phrase is detected in the sentiment, pluralize it and ask for more input on that topic\n",
        "   5. Print response\n",
        "3. loop back to step 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpFc3nGWL4yR",
        "outputId": "38bde2f7-1b84-411f-8ecb-b10bbc485700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, I am Marvin, the simple robot.\n",
            "You can end this conversation at any time by typing 'bye'\n",
            "After typing each answer, press 'enter'\n",
            "How are you today?\n",
            "It was nice talking to you, goodbye!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from textblob import TextBlob\n",
        "from textblob.np_extractors import ConllExtractor\n",
        "import nltk\n",
        "\n",
        "# DONE make these quiet: we don't want to see the download messages\n",
        "nltk.download('punkt', quiet=True)\n",
        "extractor = ConllExtractor()\n",
        "\n",
        "\n",
        "nltk.download('conll2000', quiet=True)\n",
        "\n",
        "print(\"Hello, I am Marvin, the simple robot.\")\n",
        "print(\"You can end this conversation at any time by typing 'bye'\")\n",
        "print(\"After typing each answer, press 'enter'\")\n",
        "print(\"How are you today?\")\n",
        "\n",
        "while True:\n",
        "        # wait for the user to enter some text\n",
        "        user_input = input(\"> \")\n",
        "\n",
        "        if user_input.lower() == \"bye\":\n",
        "            # if they typed in 'bye' (or even BYE, ByE, byE etc.), break out of the loop\n",
        "            break\n",
        "        else:\n",
        "            # Create a TextBlob based on the user input. Then extract the noun phrases\n",
        "            user_input_blob = TextBlob(user_input, np_extractor=extractor)\n",
        "            np = user_input_blob.noun_phrases\n",
        "            response = \"\"\n",
        "            if user_input_blob.polarity <= -0.5:\n",
        "                response = \"Oh dear, that sounds bad. \"\n",
        "            elif user_input_blob.polarity <= 0:\n",
        "                response = \"Hmm, that's not great. \"\n",
        "            elif user_input_blob.polarity <= 0.5:\n",
        "                response = \"Well, that sounds positive. \"\n",
        "            elif user_input_blob.polarity <= 1:\n",
        "                response = \"Wow, that sounds great. \"\n",
        "\n",
        "            if len(np) != 0:\n",
        "                # There was at least one noun phrase detected, so ask about that and pluralise it\n",
        "                # e.g. cat -> cats or mouse -> mice\n",
        "                response = response + \"Can you tell me more about \" + np[0].pluralize() + \"?\"\n",
        "            else:\n",
        "                response = response + \"Can you tell me more?\"\n",
        "            print(response)\n",
        "\n",
        "print(\"It was nice talking to you, goodbye!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sLRpRT9L4yR"
      },
      "source": [
        "# 6.3 Translation and sentiment analysis with ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwbsDAIUL4yR"
      },
      "source": [
        "### 6.3.1 Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFZ4ol3qL4yR",
        "outputId": "569a61d7-39c8-4ef0-910b-253ed3d96a6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextBlob(\"Det er en sandhed, der universelt er anerkendt, at en enkelt mand, der er i besiddelse af en lykke, skal v√¶re i mangel p√• en kone!\")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "blob = TextBlob(\n",
        "    \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife!\"\n",
        ")\n",
        "blob.translate(from_lang=\"en\",to=\"da\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-OjMWiWL4yS"
      },
      "source": [
        "> ‚ùì What's going on here? and why is TextBlob so good at translation? \n",
        "\n",
        "Well, behind the scenes, it's using Google translate, a sophisticated AI able to parse millions of phrases to predict the best strings for the task at hand. There's nothing manual going on here and you need an internet connection to use `blob.translate`.\n",
        "\n",
        "‚úÖ Try some more sentences. Which is better, ML or human translation? In which cases?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13cZNCgyL4yS"
      },
      "source": [
        "### 6.3.2 Sentiment\n",
        "Sentiment is measured in with a *polarity* of -1 to 1, meaning -1 is the most negative sentiment, and 1 is the most positive.\n",
        "\n",
        "Sentiment is also measured with an 0 - 1 score for objectivity (0) and subjectivity (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s298B_FL4yS",
        "outputId": "29b68ba9-bcdb-4f11-cdc1-effdc0035885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. has a sentiment of Sentiment(polarity=0.20952380952380953, subjectivity=0.27142857142857146)\n",
            "Darcy, as well as Elizabeth, really loved them; and they were both ever sensible of the warmest gratitude towards the persons who, by bringing her into Derbyshire, had been the means of uniting them. has a sentiment of Sentiment(polarity=0.7, subjectivity=0.8)\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "quote1 = \"\"\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\"\"\n",
        "\n",
        "quote2 = \"\"\"Darcy, as well as Elizabeth, really loved them; and they were both ever sensible of the warmest gratitude towards the persons who, by bringing her into Derbyshire, had been the means of uniting them.\"\"\"\n",
        "\n",
        "sentiment1 = TextBlob(quote1).sentiment\n",
        "sentiment2 = TextBlob(quote2).sentiment\n",
        "\n",
        "print(quote1 + \" has a sentiment of \" + str(sentiment1))\n",
        "print(quote2 + \" has a sentiment of \" + str(sentiment2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKMJQoXwL4yS"
      },
      "source": [
        "#### Challenge - check sentiment polarity\n",
        "Our task is to determine, using sentiment polarity, if *Pride and Prejudice* has more absolutely positive sentences than absolutely negative ones. For this task, you may assume that a polarity score of 1 or -1 is absolutely positive or negative respectively.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. ~~Download a [copy of Pride and Prejudice](https://www.gutenberg.org/files/1342/1342-h/1342-h.htm) from Project Gutenberg as a .txt file. Remove the metadata at the start and end of the file, leaving only the original text~~ Cumhur used \n",
        "\n",
        "`curl https://raw.githubusercontent.com/cs109/2015lab8/master/data/pride_and_prejudice.txt -o pride.txt` \n",
        "\n",
        "and did not clean up (as metadata is neutral).\n",
        "\n",
        "2. Open the file in Python and extract the contents as a string\n",
        "\n",
        "3. Create a TextBlob using the book string\n",
        "\n",
        "4. Analyse each sentence in the book in a loop\n",
        "   4.1. If the polarity is 1 or -1 store the sentence in an array or list of positive or negative messages\n",
        "\n",
        "5. At the end, print out all the positive sentences and negative sentences (separately) and the number of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "D-OUYqP2L4yS"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QC4NiiufL4yS"
      },
      "outputs": [],
      "source": [
        "# You should download the book text, clean it, and import it here\n",
        "with open(\"pride.txt\", encoding=\"utf8\") as f:\n",
        "    file_contents = f.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ej8z_t0CL4yS"
      },
      "outputs": [],
      "source": [
        "book_pride = TextBlob(file_contents)\n",
        "positive_sentiment_sentences = []\n",
        "negative_sentiment_sentences = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wNK1smxLL4yS"
      },
      "outputs": [],
      "source": [
        "for sentence in book_pride.sentences:\n",
        "    if sentence.sentiment.polarity == 1:\n",
        "        positive_sentiment_sentences.append(sentence)\n",
        "    if sentence.sentiment.polarity == -1:\n",
        "        negative_sentiment_sentences.append(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OvcBxdyL4yS",
        "outputId": "bb4c729c-c8a8-49d1-c05b-5a88f49d09b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 39 most positive sentences:\n",
            "+ \"What an excellent father you have, girls!\"\n",
            "+ Everybody said how wellshe looked; and Mr. Bingley thought her quite beautiful, and danced withher twice!\n",
            "+ He walked here, and he walked there, fancying himself so verygreat!\n",
            "+ Elizabeth assured him that she could suit herself perfectly with thosein the room.\n",
            "+ What a delightful library you have atPemberley, Mr.\n",
            "+ Her performance on the pianoforte is exquisite.\"\n",
            "+ yes--I understand you perfectly.\"\n",
            "+ \"I am perfectly convinced by it that Mr. Darcy has no defect.\n",
            "+ \"It _is_ wonderful,\" replied Wickham, \"for almost all his actions maybe traced to pride; and pride had often been his best friend.\n",
            "+ Family pride, and _filial_ pride--for he is very proud of whathis father was--have done this.\n",
            "+ _That_ would be the greatest misfortune of all!\n",
            "+ How wonderfully these sort of things occur!\n",
            "+ She owedher greatest relief to her friend Miss Lucas, who often joined them, andgood-naturedly engaged Mr. Collins's conversation to herself.\n",
            "+ \"An excellent consolation in its way,\" said Elizabeth, \"but it will notdo for _us_.\n",
            "+ The improvementof spending a night in London was added in time, and the plan becameperfect as plan could be.\n",
            "+ It is the greatest of favourswhen Miss de Bourgh comes in.\"\n",
            "+ Anne would havebeen a delightful performer, had her health allowed her to learn.\"\n",
            "+ \"Perfectly so, I thank you.\"\n",
            "+ She is avery great favourite with some ladies of my acquaintance, Mrs. Hurst andMiss Bingley.\n",
            "+ Perhaps thisconcealment, this disguise was beneath me; it is done, however, and itwas done for the best.\n",
            "+ I have the greatest dislike inthe world to that sort of thing.\n",
            "+ cried Elizabeth, with the greatest satisfaction.\n",
            "+ Charlotte is anexcellent manager, I dare say.\n",
            "+ \"His father was an excellent man,\" said Mrs. Gardiner.\n",
            "+ \"He is perfectly well behaved, polite, and unassuming,\" said her uncle.\n",
            "+ On reaching the house, they were shown through the hall into the saloon,whose northern aspect rendered it delightful for summer.\n",
            "+ Ourdistress, my dear Lizzy, is very great.\n",
            "+ And tell my dear Lydia not togive any directions about her clothes till she has seen me, for she doesnot know which are the best warehouses.\n",
            "+ We acted with the best intentions.\"\n",
            "+ It now occurred to the girls that their mother was in all likelihoodperfectly ignorant of what had happened.\n",
            "+ \"This is delightful indeed!\n",
            "+ I am so happy!\n",
            "+ But, however, he is very welcometo come to Netherfield, if he likes it.\n",
            "+ Happy shall I be, when his stay at Netherfield is over!\"\n",
            "+ You will be a very happy woman.\"\n",
            "+ my dear, dear Jane, I am sohappy!\n",
            "+ If I could but see _you_ as happy!\n",
            "+ He is perfectly amiable.\n",
            "+ Youridea of the ponies is delightful.\n"
          ]
        }
      ],
      "source": [
        "print(\"The \" + str(len(positive_sentiment_sentences)) + \" most positive sentences:\")\n",
        "for sentence in positive_sentiment_sentences:\n",
        "    print(\"+ \" + str(sentence.replace(\"\\n\", \"\").replace(\"      \", \" \")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXnWKelGL4yS",
        "outputId": "853e90df-4f9a-461e-a3c7-39b5ad60ff8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 18 most negative sentences:\n",
            "- shocking!\"\n",
            "- Everybody is disgusted with his pride.\n",
            "- \"This is quite shocking!\n",
            "- What canhave induced him to behave so cruelly?\"\n",
            "- His dispositionmust be dreadful.\"\n",
            "- To finda man agreeable whom one is determined to hate!\n",
            "- \"You shall hear then--but prepare yourself for something very dreadful.\n",
            "- The pause was to Elizabeth's feelingsdreadful.\n",
            "- \"Wickham sovery bad!\n",
            "- The separationbetween her and her family was rather noisy than pathetic.\n",
            "- It would be dreadful!\n",
            "- It is every way horrible!\"\n",
            "- \"Oh, yes!--that, that is the worst of all.\n",
            "- \"She is so fond of Mrs. Forster,\" said she, \"it will be quite shockingto send her away!\n",
            "- It was all over before I arrived; so my curiosity was not sodreadfully racked as _yours_ seems to have been.\n",
            "- Hecalled it, therefore, his duty to step forward, and endeavour to remedyan evil which had been brought on by himself.\n",
            "- \"Hate you!\n",
            "- You were disgusted with the women who were always speaking,and looking, and thinking for _your_ approbation alone.\n"
          ]
        }
      ],
      "source": [
        "print(\"The \" + str(len(negative_sentiment_sentences)) + \" most negative sentences:\")\n",
        "for sentence in negative_sentiment_sentences:\n",
        "    print(\"- \" + str(sentence.replace(\"\\n\", \"\").replace(\"      \", \" \")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIVmJt8-L4yT"
      },
      "source": [
        "‚úÖ Knowledge Check: Consult to the [3-Translation-Sentiment/README.md](../3-Translation-Sentiment/README.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTIzqIuJL4yT"
      },
      "source": [
        "# 6.4 Hotel Reviews 1\n",
        "\n",
        "See [4-Hotel-Reviews-1/README.md](../4-Hotel-Reviews-1/README.md) for details and the questions we ask.\n",
        "\n",
        "‚ùóÔ∏èIf you don't like downloading from Kaggle or elsewhere as we do, you could try if you have huggingface =datasets= installed:\n",
        " ```python\n",
        " from datasets import load_dataset\n",
        " dataset = load_dataset(\"ashraq/hotel-reviews\")\n",
        " df = dataset[\"train\"].to_pandas()\n",
        " df.head() # note the data HF has only 3 columns and already cleaned\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DuZyBkFOL4yT"
      },
      "outputs": [],
      "source": [
        "## EDA\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wAq9OiLLL4yT"
      },
      "outputs": [],
      "source": [
        "def get_difference_review_avg(row):\n",
        "    return row[\"Average_Score\"] - row[\"Calc_Average_Score\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuhuGIU6L4yT",
        "outputId": "56a31ccc-2484-441c-c627-f887f70ba64e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data file now, this could take a while depending on file size\n",
            "Loading took 1.15 seconds\n"
          ]
        }
      ],
      "source": [
        "# Load the hotel reviews from CSV\n",
        "print(\"Loading data file now, this could take a while depending on file size\")\n",
        "start = time.time()\n",
        "df = pd.read_csv('Hotel_Reviews.csv')\n",
        "end = time.time()\n",
        "print(\"Loading took \" + str(round(end - start, 2)) + \" seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1cT3oniL4yT",
        "outputId": "9d27fa9f-3856-45e0-f35c-b6ee745ff108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of the data (rows, cols) is (515738, 18)\n"
          ]
        }
      ],
      "source": [
        "# What shape is the data (rows, columns)?\n",
        "print(\"The shape of the data (rows, cols) is \" + str(df.shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "yvYmh4Ohb-H1",
        "outputId": "d61266ee-0ae8-48f4-85be-b9c97f597324"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Hotel_Name",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Hotel_Address",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Total_Number_of_Reviews",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Average_Score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Reviewer_Score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Negative_Sentiment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Positive_Sentiment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Reviewer_Nationality",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Leisure_trip",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Couple",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Solo_traveler",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Business_trip",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Group",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Family_with_young_children",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Family_with_older_children",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "With_a_pet",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Negative_Review",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Positive_Review",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "08c9e835-6787-4581-bf69-e3b26613fb3c",
              "rows": [
                [
                  "0",
                  "South Place Hotel",
                  "London, United Kingdom",
                  "769",
                  "9.3",
                  "2.5",
                  "-0.9849",
                  "-0.982",
                  " Brazil ",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "No windows claustrophobic place even superior rooms least mine We going stay twice hotel I think got upset I like lack windows cheap category bad tretament service terrible room service taste plastic VERY Expensive awful foo seriously noise lot noise seems like dance club soundproff rooms always throw parties whatever call loud music sunday lunch trying rest pointing I sent like three e mails advice alerting matter silence sleep rest 4th floor I think got upset I cancelled last reservation Got asking I cancelled guess They MADE UP ridiculous story smoking alert room total lie Nobody called asking supposedly happening three men including sort manager knocked door like police knocking door criminal embarassing terrifying situation hotels world Corsica 5 star hotel boutique Cyprus Turkey Greece Iceland like 15 countries life never similar I could imagine hotel worst nightmares I MY UNDERWEAR AND THEY INSISTED TO COME IN THE ROOM THEY CAME NOTHING THEY THREW US OUT OF THE HOTEL I payed another night apex I use stay London many many times shocked seeing crying scared tried help ways I really describe threat another guy left hotel immediately literally threw us I returned sort manager said going call police take us away We panic leaving PLACE NOBODY refund us initially guy bunch intimidating kicking door agreed refunding night",
                  "Bathroom Shower We going stay twice hotel 2 nights row 3 days last days London Lack windows cheap category bad tretament service terrible room service taste plastic VERY expensive awful food seriously Noise A LOT OF noise caused seems like dance club soundproff rooms always throw parties whatever call loud music sunday lunch trying rest pointing I sent like three e mails advice alerting matter silence sleep rest 4th floor I think got upset I cancelled last reservation end trip 27th 30th Got directly asking I cancelled booking com guess They MADE UP ridiculous story smoke alert room total lie Nobody called asking supposedly happening three men including sort manager knocked door like police knocking door criminal found anything returned SURREALISTIC embarassing terrifying situation hotels world entire lives normally type situation given call floor evacuated us Corsica 5 star hotel boutique Cyprus Turkey Greece Iceland like 15 countries life never similar I could imagine hotel worst nightmares I MY UNDERWEAR AND THEY INSISTED TO COME IN THE ROOM THEY CAME NOTHING THEY THREW US OUT OF THE HOTEL I payed another night apex I use stay London many many times shocked seeing crying scared tried help ways I really describe threat another guy left hotel immediately literally threw us I returned sort manager said going call police take us away"
                ],
                [
                  "1",
                  "Park Plaza County Hall London",
                  "London, United Kingdom",
                  "6117",
                  "8.4",
                  "3.8",
                  "-0.978",
                  "-0.978",
                  " Saudi Arabia ",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "I completely disappointed mad since reception staff generally unfriendly More specifically Brad Brad talks guests attitude upper position always thinks right Without notification alignment deducted whole amount stay credit card instead preauthorization He claimed hotel policy deduct whole amount stay 7 nights I told I aware policy asked show written He said written anywhere hotel supposed show guests policies I told I disagree especially related terms payments I asked speak manager said I manager Then I asked speak superior Then said I cancel sales preauthoriz amount I told work take least 5 days reverse payment He said sure take hours Unfortunately cancelled took 5 working days During period amount deducted stuck banks hotel keeps trying preauthoriz amount notifications bank keeps coming phone failed attempted Of course attempts hurt credit records bank I devastated angry one said sorry compensation provided Horrible customer experience",
                  "I completely disappointed mad since reception staff generally unfriendly More specifically Brad Brad talks guests attitude upper position always thinks right Without notification alignment deducted whole amount stay credit card instead preauthorization He claimed hotel policy deduct whole amount stay 7 nights I told I aware policy asked show written He said written anywhere hotel supposed show guests policies I told I disagree especially related terms payments I asked speak manager said I manager Then I asked speak superior Then said I cancel sales preauthoriz amount I told work take least 5 days reverse payment He said sure take hours Unfortunately cancelled took 5 working days During period amount deducted stuck banks hotel keeps trying preauthoriz amount notifications bank keeps coming phone failed attempted Of course attempts hurt credit records bank I devastated angry one said sorry compensation provided Horrible customer experience"
                ],
                [
                  "2",
                  "Britannia International Hotel Canary Wharf",
                  "London, United Kingdom",
                  "9086",
                  "6.8",
                  "3.3",
                  "-0.4767",
                  "-0.9751",
                  " Australia ",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "everything terrible",
                  "get everything extra internet parking breakfast We spent 5 weeks travelling around England found worst hotel stayed The room window basement bed terrible chair room broken asked new one one replaced also broken Staff rude know hotel terrible also must given dont care attitude The foyer outdated dirty"
                ],
                [
                  "3",
                  "Caesar Hotel",
                  "London, United Kingdom",
                  "1164",
                  "8.3",
                  "3.3",
                  "0.1082",
                  "-0.9721",
                  " United States Minor Outlying Islands ",
                  "1",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "Everything I worst experience ever best friend Really sad management really care problems going",
                  "I didnt like anythig Room small Asked upgrade denied I told reception I staying 6 days 2 3 said matter dont upgrade people want another room pay The bathroom horrible odor complained The AC sistem ridiculous call every night put In 4 day sheets dirty I tell change sheets They vaccum bathroom Everything ever asked NO answer The reception awful 4 star boutique hotel The worst part ask one night go Italian Restaurant send us cheap place call I believe Bonissimo I pasta Salmon The next day I woke alergy face went pharmacy medication The reception never said Hello even Good Night friendly I go awful experience many hotels choose I think Booking com place hotel 4 star hotel"
                ],
                [
                  "4",
                  "Hotel Da Vinci",
                  "Milan, Italy",
                  "16670",
                  "7.8",
                  "2.5",
                  "0.0",
                  "-0.9703",
                  " United Kingdom ",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "No Negative",
                  "Very rude manager abusive staff reception Dirty unclean bathroom Cold water shower Cold food worst seating arrangement breakfast hall Bad location View hell Never coming back Waste money"
                ]
              ],
              "shape": {
                "columns": 18,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hotel_Name</th>\n",
              "      <th>Hotel_Address</th>\n",
              "      <th>Total_Number_of_Reviews</th>\n",
              "      <th>Average_Score</th>\n",
              "      <th>Reviewer_Score</th>\n",
              "      <th>Negative_Sentiment</th>\n",
              "      <th>Positive_Sentiment</th>\n",
              "      <th>Reviewer_Nationality</th>\n",
              "      <th>Leisure_trip</th>\n",
              "      <th>Couple</th>\n",
              "      <th>Solo_traveler</th>\n",
              "      <th>Business_trip</th>\n",
              "      <th>Group</th>\n",
              "      <th>Family_with_young_children</th>\n",
              "      <th>Family_with_older_children</th>\n",
              "      <th>With_a_pet</th>\n",
              "      <th>Negative_Review</th>\n",
              "      <th>Positive_Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>South Place Hotel</td>\n",
              "      <td>London, United Kingdom</td>\n",
              "      <td>769</td>\n",
              "      <td>9.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>-0.9849</td>\n",
              "      <td>-0.9820</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No windows claustrophobic place even superior ...</td>\n",
              "      <td>Bathroom Shower We going stay twice hotel 2 ni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Park Plaza County Hall London</td>\n",
              "      <td>London, United Kingdom</td>\n",
              "      <td>6117</td>\n",
              "      <td>8.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-0.9780</td>\n",
              "      <td>-0.9780</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I completely disappointed mad since reception ...</td>\n",
              "      <td>I completely disappointed mad since reception ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Britannia International Hotel Canary Wharf</td>\n",
              "      <td>London, United Kingdom</td>\n",
              "      <td>9086</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>-0.4767</td>\n",
              "      <td>-0.9751</td>\n",
              "      <td>Australia</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>everything terrible</td>\n",
              "      <td>get everything extra internet parking breakfas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Caesar Hotel</td>\n",
              "      <td>London, United Kingdom</td>\n",
              "      <td>1164</td>\n",
              "      <td>8.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.1082</td>\n",
              "      <td>-0.9721</td>\n",
              "      <td>United States Minor Outlying Islands</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Everything I worst experience ever best friend...</td>\n",
              "      <td>I didnt like anythig Room small Asked upgrade ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hotel Da Vinci</td>\n",
              "      <td>Milan, Italy</td>\n",
              "      <td>16670</td>\n",
              "      <td>7.8</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.9703</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Negative</td>\n",
              "      <td>Very rude manager abusive staff reception Dirt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Hotel_Name           Hotel_Address  \\\n",
              "0                           South Place Hotel  London, United Kingdom   \n",
              "1               Park Plaza County Hall London  London, United Kingdom   \n",
              "2  Britannia International Hotel Canary Wharf  London, United Kingdom   \n",
              "3                                Caesar Hotel  London, United Kingdom   \n",
              "4                              Hotel Da Vinci            Milan, Italy   \n",
              "\n",
              "   Total_Number_of_Reviews  Average_Score  Reviewer_Score  Negative_Sentiment  \\\n",
              "0                      769            9.3             2.5             -0.9849   \n",
              "1                     6117            8.4             3.8             -0.9780   \n",
              "2                     9086            6.8             3.3             -0.4767   \n",
              "3                     1164            8.3             3.3              0.1082   \n",
              "4                    16670            7.8             2.5              0.0000   \n",
              "\n",
              "   Positive_Sentiment                    Reviewer_Nationality  Leisure_trip  \\\n",
              "0             -0.9820                                 Brazil              0   \n",
              "1             -0.9780                           Saudi Arabia              1   \n",
              "2             -0.9751                              Australia              1   \n",
              "3             -0.9721   United States Minor Outlying Islands              1   \n",
              "4             -0.9703                         United Kingdom              1   \n",
              "\n",
              "   Couple  Solo_traveler  Business_trip  Group  Family_with_young_children  \\\n",
              "0       1              0              0      0                           0   \n",
              "1       0              0              0      0                           1   \n",
              "2       1              0              0      0                           0   \n",
              "3       0              0              0      1                           0   \n",
              "4       0              0              0      0                           1   \n",
              "\n",
              "   Family_with_older_children  With_a_pet  \\\n",
              "0                           0           0   \n",
              "1                           0           0   \n",
              "2                           0           0   \n",
              "3                           0           0   \n",
              "4                           0           0   \n",
              "\n",
              "                                     Negative_Review  \\\n",
              "0  No windows claustrophobic place even superior ...   \n",
              "1  I completely disappointed mad since reception ...   \n",
              "2                                everything terrible   \n",
              "3  Everything I worst experience ever best friend...   \n",
              "4                                        No Negative   \n",
              "\n",
              "                                     Positive_Review  \n",
              "0  Bathroom Shower We going stay twice hotel 2 ni...  \n",
              "1  I completely disappointed mad since reception ...  \n",
              "2  get everything extra internet parking breakfas...  \n",
              "3  I didnt like anythig Room small Asked upgrade ...  \n",
              "4  Very rude manager abusive staff reception Dirt...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WvR4zM5wL4yT"
      },
      "outputs": [],
      "source": [
        "# value_counts() creates a Series object that has index and values\n",
        "#                in this case, the country and the frequency they occur in reviewer nationality\n",
        "nationality_freq = df[\"Reviewer_Nationality\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKzRwHRxL4yT",
        "outputId": "1b770bcf-01a6-458a-99bf-3eda8acdd180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The highest frequency reviewer nationality is United Kingdom with 245246 reviews.\n"
          ]
        }
      ],
      "source": [
        "# What reviewer nationality is the most common in the dataset?\n",
        "print(\"The highest frequency reviewer nationality is \" + str(nationality_freq.index[0]).strip() + \" with \" + str(nationality_freq.iloc[0]) + \" reviews.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnAIP3zaL4yT",
        "outputId": "ff7469b2-858b-40bd-aa7f-f0da81ff5a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The top 10 highest frequency reviewer nationalities are:\n",
            "Reviewer_Nationality\n",
            "United Kingdom               245246\n",
            "United States of America      35437\n",
            "Australia                     21686\n",
            "Ireland                       14827\n",
            "United Arab Emirates          10235\n",
            "Saudi Arabia                   8951\n",
            "Netherlands                    8772\n",
            "Switzerland                    8678\n",
            "Germany                        7941\n",
            "Canada                         7894\n"
          ]
        }
      ],
      "source": [
        "# What is the top 10 most common nationalities and their frequencies?\n",
        "print(\"The top 10 highest frequency reviewer nationalities are:\")\n",
        "print(nationality_freq[0:10].to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uqc31gtL4yT",
        "outputId": "da5c727b-6f67-4c6c-cdb7-06bc1e17ecb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 227 unique nationalities in the dataset\n"
          ]
        }
      ],
      "source": [
        "# How many unique nationalities are there?\n",
        "print(\"There are \" + str(nationality_freq.index.size) + \" unique nationalities in the dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vQuZ4ECL4yT",
        "outputId": "b03e7cde-76d6-41b2-cf32-111c08363ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.\n",
            "The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.\n",
            "The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.\n",
            "The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.\n",
            "The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.\n",
            "The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.\n",
            "The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.\n",
            "The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.\n",
            "The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.\n",
            "The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.\n"
          ]
        }
      ],
      "source": [
        "# What was the most frequently reviewed hotel for the top 10 nationalities - print the hotel and number of reviews\n",
        "for nat in nationality_freq[:10].index:\n",
        "   # First, extract all the rows that match the criteria into a new dataframe\n",
        "   nat_df = df[df[\"Reviewer_Nationality\"] == nat]\n",
        "   # Now get the hotel freq\n",
        "   freq = nat_df[\"Hotel_Name\"].value_counts()\n",
        "   print(\"The most reviewed hotel for \" + str(nat).strip() + \" was \" + str(freq.index[0]) + \" with \" + str(freq.iloc[0]) + \" reviews.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BbIoWcuLL4yT"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Additional_Number_of_Scoring', 'Review_Date', 'Review_Total_Negative_Word_Counts', 'Review_Total_Positive_Word_Counts', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Tags', 'days_since_review', 'lat', 'lng'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# How many reviews are there per hotel (frequency count of hotel) and do the results match the value in `Total_Number_of_Reviews`?\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# First create a new dataframe based on the old one, removing the uneeded columns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m hotel_freq_df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHotel_Address\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdditional_Number_of_Scoring\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReview_Date\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAverage_Score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReviewer_Nationality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNegative_Review\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReview_Total_Negative_Word_Counts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPositive_Review\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReview_Total_Positive_Word_Counts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTotal_Number_of_Reviews_Reviewer_Has_Given\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReviewer_Score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdays_since_review\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found\u001b[39;00m\n\u001b[32m      5\u001b[39m hotel_freq_df[\u001b[33m'\u001b[39m\u001b[33mTotal_Reviews_Found\u001b[39m\u001b[33m'\u001b[39m] = hotel_freq_df.groupby(\u001b[33m'\u001b[39m\u001b[33mHotel_Name\u001b[39m\u001b[33m'\u001b[39m).transform(\u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
            "\u001b[31mKeyError\u001b[39m: \"['Additional_Number_of_Scoring', 'Review_Date', 'Review_Total_Negative_Word_Counts', 'Review_Total_Positive_Word_Counts', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Tags', 'days_since_review', 'lat', 'lng'] not found in axis\""
          ]
        }
      ],
      "source": [
        "# How many reviews are there per hotel (frequency count of hotel) and do the results match the value in `Total_Number_of_Reviews`?\n",
        "# First create a new dataframe based on the old one, removing the uneeded columns\n",
        "hotel_freq_df = df.drop([\"Hotel_Address\", \"Additional_Number_of_Scoring\", \"Review_Date\", \"Average_Score\", \"Reviewer_Nationality\", \"Negative_Review\", \"Review_Total_Negative_Word_Counts\", \"Positive_Review\", \"Review_Total_Positive_Word_Counts\", \"Total_Number_of_Reviews_Reviewer_Has_Given\", \"Reviewer_Score\", \"Tags\", \"days_since_review\", \"lat\", \"lng\"], axis = 1)\n",
        "# Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found\n",
        "hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')\n",
        "# Get rid of all the duplicated rows\n",
        "hotel_freq_df = hotel_freq_df.drop_duplicates(subset = [\"Hotel_Name\"])\n",
        "# print()\n",
        "# print(hotel_freq_df.to_string())\n",
        "# print(str(hotel_freq_df.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1WsRMEdL4yT",
        "outputId": "55989cfa-585a-44b4-e46c-d74569cd065c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Average_Score_Difference  Average_Score  Calc_Average_Score  \\\n",
            "0                            0.0            9.3                 9.3   \n",
            "4050                         0.0            6.8                 6.8   \n",
            "4046                         0.0            9.0                 9.0   \n",
            "4038                         0.0            8.1                 8.1   \n",
            "4028                         0.0            8.7                 8.7   \n",
            "...                          ...            ...                 ...   \n",
            "999                          0.0            7.1                 7.1   \n",
            "997                          0.0            8.4                 8.4   \n",
            "987                          0.0            8.5                 8.5   \n",
            "1018                         0.0            9.1                 9.1   \n",
            "198460                       0.0            8.7                 8.7   \n",
            "\n",
            "                               Hotel_Name  \n",
            "0                       South Place Hotel  \n",
            "4050              Eurohotel Diagonal Port  \n",
            "4046                         Select Hotel  \n",
            "4038               Grange Clarendon Hotel  \n",
            "4028    Molitor Paris MGallery by Sofitel  \n",
            "...                                   ...  \n",
            "999           Royal Garden Champs Elysees  \n",
            "997      STRAF a Member of Design Hotels   \n",
            "987     NH Collection Barcelona Constanza  \n",
            "1018           citizenM London Shoreditch  \n",
            "198460                   Room Mate Gerard  \n",
            "\n",
            "[1492 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# While there is an `Average_Score` for each hotel according to the dataset,\n",
        "# you can also calculate an average score (getting the average of all reviewer scores in the dataset for each hotel)\n",
        "# Add a new column to your dataframe with the column header `Calc_Average_Score` that contains that calculated average.\n",
        "df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)\n",
        "# Add a new column with the difference between the two average scores\n",
        "df[\"Average_Score_Difference\"] = df.apply(get_difference_review_avg, axis = 1)\n",
        "# Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)\n",
        "review_scores_df = df.drop_duplicates(subset = [\"Hotel_Name\"])\n",
        "# Sort the dataframe to find the lowest and highest average score difference\n",
        "review_scores_df = review_scores_df.sort_values(by=[\"Average_Score_Difference\"])\n",
        "print(review_scores_df[[\"Average_Score_Difference\", \"Average_Score\", \"Calc_Average_Score\", \"Hotel_Name\"]])\n",
        "# Do any hotels have the same (rounded to 1 decimal place) `Average_Score` and `Calc_Average_Score`?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFYEihQ4L4yT"
      },
      "source": [
        "üí°As we proceed to NLP, take this opportunity to read through the '[NLTK book](https://www.nltk.org/book/)' and try out its exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnhcRLTKL4yT"
      },
      "source": [
        "# 6.5-Hotel-Reviews-2: Sentiment Analysis\n",
        "\n",
        "Now that you have explored the dataset in detail, it's time to filter the columns and then use NLP techniques on the dataset to gain new insights about the hotels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enbqlm86L4yU"
      },
      "source": [
        "### Exercise: a bit more data processing\n",
        "\n",
        "Clean the data just a bit more. Add columns that will be useful later, change the values in other columns, and drop certain columns completely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "B36iB40cL4yU"
      },
      "outputs": [],
      "source": [
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2ZL8ELpOL4yU"
      },
      "outputs": [],
      "source": [
        "def replace_address(row):\n",
        "    if \"Netherlands\" in row[\"Hotel_Address\"]:\n",
        "        return \"Amsterdam, Netherlands\"\n",
        "    elif \"Barcelona\" in row[\"Hotel_Address\"]:\n",
        "        return \"Barcelona, Spain\"\n",
        "    elif \"United Kingdom\" in row[\"Hotel_Address\"]:\n",
        "        return \"London, United Kingdom\"\n",
        "    elif \"Milan\" in row[\"Hotel_Address\"]:\n",
        "        return \"Milan, Italy\"\n",
        "    elif \"France\" in row[\"Hotel_Address\"]:\n",
        "        return \"Paris, France\"\n",
        "    elif \"Vienna\" in row[\"Hotel_Address\"]:\n",
        "        return \"Vienna, Austria\"\n",
        "    else:\n",
        "        return row.Hotel_Address\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "B4X5tN6RL4yU"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['lat', 'lng'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# dropping columns we will not use:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
            "\u001b[31mKeyError\u001b[39m: \"['lat', 'lng'] not found in axis\""
          ]
        }
      ],
      "source": [
        "# dropping columns we will not use:\n",
        "df.drop([\"lat\", \"lng\"], axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ixaFNvlJL4yY"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Additional_Number_of_Scoring'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mHotel_Address\u001b[39m\u001b[33m\"\u001b[39m] = df.apply(replace_address, axis = \u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Drop `Additional_Number_of_Scoring`\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdditional_Number_of_Scoring\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
            "\u001b[31mKeyError\u001b[39m: \"['Additional_Number_of_Scoring'] not found in axis\""
          ]
        }
      ],
      "source": [
        "# Replace all the addresses with a shortened, more useful form\n",
        "df[\"Hotel_Address\"] = df.apply(replace_address, axis = 1)\n",
        "# Drop `Additional_Number_of_Scoring`\n",
        "df.drop([\"Additional_Number_of_Scoring\"], axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jHsjqtMGL4yY"
      },
      "outputs": [],
      "source": [
        "# Replace `Total_Number_of_Reviews` and `Average_Score` with our own calculated values\n",
        "df.Average_Score = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "5Oz7kPUyL4yY"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'Tags'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[32m/var/folders/j4/0lv7gs9s385byhj07wh6tch40000gp/T/ipykernel_70642/3988606136.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# The file Hotel_Reviews_Tags.py, identifies the most important tags\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Leisure trip, Couple, Solo traveler, Business trip, Group combined with Travelers with friends,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Family with young children, Family with older children, With a pet\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df[\u001b[33m\"Leisure_trip\"\u001b[39m] = df.Tags.apply(\u001b[38;5;28;01mlambda\u001b[39;00m tag: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"Leisure trip\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m tag \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m      7\u001b[39m df[\u001b[33m\"Couple\"\u001b[39m] = df.Tags.apply(\u001b[38;5;28;01mlambda\u001b[39;00m tag: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"Couple\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m tag \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m      8\u001b[39m df[\u001b[33m\"Solo_traveler\"\u001b[39m] = df.Tags.apply(\u001b[38;5;28;01mlambda\u001b[39;00m tag: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"Solo traveler\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m tag \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m df[\u001b[33m\"Business_trip\"\u001b[39m] = df.Tags.apply(\u001b[38;5;28;01mlambda\u001b[39;00m tag: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"Business trip\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m tag \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n",
            "\u001b[32m~/vc/teaching/ML-For-Beginners/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
            "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'Tags'"
          ]
        }
      ],
      "source": [
        "# Process the Tags into new columns\n",
        "# The file Hotel_Reviews_Tags.py, identifies the most important tags\n",
        "# Leisure trip, Couple, Solo traveler, Business trip, Group combined with Travelers with friends,\n",
        "# Family with young children, Family with older children, With a pet\n",
        "\n",
        "df[\"Leisure_trip\"] = df.Tags.apply(lambda tag: 1 if \"Leisure trip\" in tag else 0)\n",
        "df[\"Couple\"] = df.Tags.apply(lambda tag: 1 if \"Couple\" in tag else 0)\n",
        "df[\"Solo_traveler\"] = df.Tags.apply(lambda tag: 1 if \"Solo traveler\" in tag else 0)\n",
        "df[\"Business_trip\"] = df.Tags.apply(lambda tag: 1 if \"Business trip\" in tag else 0)\n",
        "df[\"Group\"] = df.Tags.apply(lambda tag: 1 if \"Group\" in tag or \"Travelers with friends\" in tag else 0)\n",
        "df[\"Family_with_young_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with young children\" in tag else 0)\n",
        "df[\"Family_with_older_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with older children\" in tag else 0)\n",
        "df[\"With_a_pet\"] = df.Tags.apply(lambda tag: 1 if \"With a pet\" in tag else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSC-1WI8L4yY"
      },
      "outputs": [],
      "source": [
        "# No longer need any of these columns\n",
        "df.drop([\"Review_Date\", \"Review_Total_Negative_Word_Counts\", \"Review_Total_Positive_Word_Counts\", \"days_since_review\", \"Total_Number_of_Reviews_Reviewer_Has_Given\"], axis = 1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-dD4VZ4L4yY",
        "outputId": "3fcf3221-0fbb-4cb8-c857-9ca467f4785a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving results to Hotel_Reviews_Filtered.csv\n",
            "Filtering took 44.54 seconds\n"
          ]
        }
      ],
      "source": [
        "# Saving new data file with calculated columns\n",
        "print(\"Saving results to Hotel_Reviews_Filtered.csv\")\n",
        "df.to_csv(r'Hotel_Reviews_Filtered.csv', index = False)\n",
        "end = time.time()\n",
        "print(\"Filtering took \" + str(round(end - start, 2)) + \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3qbusuUL4yY"
      },
      "source": [
        "### Exercise: load and save the filtered data for sentiment analysis\n",
        "The code skeleton should like this (assuming) independent execution:\n",
        "```python\n",
        "import time\n",
        "import pandas as pd\n",
        "import nltk as nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load the filtered hotel reviews from CSV\n",
        "df = pd.read_csv('Hotel_Reviews_Filtered.csv')\n",
        "\n",
        "# You code will be added here\n",
        "\n",
        "\n",
        "# Finally remember to save the hotel reviews with new NLP data added\n",
        "print(\"Saving results to Hotel_Reviews_NLP.csv\")\n",
        "df.to_csv(r'Hotel_Reviews_NLP.csv', index = False)\n",
        "```\n",
        "\n",
        "The actual code is below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAwg3QmNL4yY",
        "outputId": "fdb4e7bc-4971-4874-f87d-78bf5af76ba9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/cer/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/cer/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_s-q6UwjL4yY"
      },
      "outputs": [],
      "source": [
        "vader_sentiment = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "FDA1htYCL4yY"
      },
      "outputs": [],
      "source": [
        "# There are 3 possibilities of input for a review:\n",
        "# It could be \"No Negative\", in which case, return 0\n",
        "# It could be \"No Positive\", in which case, return 0\n",
        "# It could be a review, in which case calculate the sentiment\n",
        "def calc_sentiment(review):\n",
        "    if review == \"No Negative\" or review == \"No Positive\":\n",
        "        return 0\n",
        "    return vader_sentiment.polarity_scores(review)[\"compound\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcuFwJNuL4yY"
      },
      "outputs": [],
      "source": [
        "# Load the hotel reviews from CSV (already filtered)\n",
        "df = pd.read_csv(\"Hotel_Reviews_Filtered.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "iI3ZXUqAL4yY"
      },
      "outputs": [],
      "source": [
        "# Remove stop words - can be slow for a lot of text!\n",
        "# Ryan Han (ryanxjhan on Kaggle) has a great post measuring performance of different stop words removal approaches\n",
        "# https://www.kaggle.com/ryanxjhan/fast-stop-words-removal # using the approach that Ryan recommends\n",
        "start = time.time()\n",
        "cache = set(stopwords.words(\"english\"))\n",
        "def remove_stopwords(review):\n",
        "    # handle NaN / non-string values\n",
        "    if pd.isna(review):\n",
        "        return \"\"\n",
        "    if not isinstance(review, str):\n",
        "        review = str(review)\n",
        "    text = \" \".join([word for word in review.split() if word not in cache])\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "QxFn_oCQL4yZ"
      },
      "outputs": [],
      "source": [
        "# Remove the stop words from both columns\n",
        "df.Negative_Review = df.Negative_Review.apply(remove_stopwords)\n",
        "df.Positive_Review = df.Positive_Review.apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vUcQ7PKL4yZ",
        "outputId": "2463bdc3-a9fe-4220-f95e-e98709aa5ca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing stop words took 13.7 seconds\n"
          ]
        }
      ],
      "source": [
        "end = time.time()\n",
        "print(\"Removing stop words took \" + str(round(end - start, 2)) + \" seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAn4ZzzPL4yZ",
        "outputId": "d1cc83f6-282b-47cf-fe1f-09ef192980aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating sentiment columns for both positive and negative reviews\n",
            "Calculating sentiment took 56.25 seconds\n"
          ]
        }
      ],
      "source": [
        "# Add a negative sentiment and positive sentiment column. (This can take a moment, ~1,5 minute)\n",
        "print(\"Calculating sentiment columns for both positive and negative reviews\")\n",
        "start = time.time()\n",
        "df[\"Negative_Sentiment\"] = df.Negative_Review.apply(calc_sentiment)\n",
        "df[\"Positive_Sentiment\"] = df.Positive_Review.apply(calc_sentiment)\n",
        "end = time.time()\n",
        "print(\"Calculating sentiment took \" + str(round(end - start, 2)) + \" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9MIQftXL4yZ",
        "outputId": "9bd63c5a-067a-40e7-9718-8ba680ccf051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          Negative_Review  Negative_Sentiment\n",
            "123934  So bad experience memories I hotel The first n...             -0.9920\n",
            "108849  First charged twice room booked booking second...             -0.9896\n",
            "242720  The staff Had bad experience even booking Janu...             -0.9889\n",
            "108844  Everything DO NOT STAY AT THIS HOTEL I never i...             -0.9886\n",
            "144515  No WLAN room Incredibly rude restaurant staff ...             -0.9884\n",
            "...                                                   ...                 ...\n",
            "515153  I find anything hotel first I walked past hote...              0.9938\n",
            "437652  Wifi terribly slow I speed test network upload...              0.9938\n",
            "498524  The property great location There bakery next ...              0.9945\n",
            "494510  Guys I like hotel I wish return next year Howe...              0.9948\n",
            "91509   I travel lot far visited countless number hote...              0.9957\n",
            "\n",
            "[515738 rows x 2 columns]\n",
            "                                          Positive_Review  Positive_Sentiment\n",
            "0       Bathroom Shower We going stay twice hotel 2 ni...             -0.9820\n",
            "1       I completely disappointed mad since reception ...             -0.9780\n",
            "2       get everything extra internet parking breakfas...             -0.9751\n",
            "3       I didnt like anythig Room small Asked upgrade ...             -0.9721\n",
            "4       Very rude manager abusive staff reception Dirt...             -0.9703\n",
            "...                                                   ...                 ...\n",
            "515733  We celebrated wedding night Langham I commend ...              0.9985\n",
            "515734  From moment stepped doors Guesthouse Hotel sta...              0.9985\n",
            "515736  When first arrived hotel staff incredibly frie...              0.9987\n",
            "515735  We arrived super cute boutique hotel area expl...              0.9987\n",
            "515737  We went Andaz 40th birthday celebration This a...              0.9991\n",
            "\n",
            "[515738 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df = df.sort_values(by=[\"Negative_Sentiment\"], ascending=True)\n",
        "print(df[[\"Negative_Review\", \"Negative_Sentiment\"]])\n",
        "df = df.sort_values(by=[\"Positive_Sentiment\"], ascending=True)\n",
        "print(df[[\"Positive_Review\", \"Positive_Sentiment\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "AXP3AA3zL4yZ"
      },
      "outputs": [],
      "source": [
        "# Reorder the columns (This is cosmetic, but to make it easier to explore the data later)\n",
        "df = df.reindex([\"Hotel_Name\", \"Hotel_Address\", \"Total_Number_of_Reviews\", \"Average_Score\", \"Reviewer_Score\", \"Negative_Sentiment\", \"Positive_Sentiment\", \"Reviewer_Nationality\", \"Leisure_trip\", \"Couple\", \"Solo_traveler\", \"Business_trip\", \"Group\", \"Family_with_young_children\", \"Family_with_older_children\", \"With_a_pet\", \"Negative_Review\", \"Positive_Review\"], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzq_fQcaL4yZ",
        "outputId": "df0acaba-7cbb-4d0d-f2b4-3a4ac304daab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving results to Hotel_Reviews_NLP.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"Saving results to Hotel_Reviews_NLP.csv\")\n",
        "df.to_csv(r\"Hotel_Reviews_NLP.csv\", index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ml-for-beginners",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
